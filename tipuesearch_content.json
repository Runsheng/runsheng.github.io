{"pages":[{"url":"http://runsheng.github.io/winxia-tian-keng-shi-lu.html","text":"虽然大部分工作都挪到了*nix下面，但是偶尔还是在win下动动手，于是问题就来了。下面是填坑实录: 回车键 众所周知，win的换行用的是回车加换行 \\r\\n ，而不是单纯的换行符 \\n ，所以一般从win下复制到linux的文件，一般会先消灭下 \\r ， 比如 sed -i 's/\\r//g ' * 之类。 替换完了换成vi看一眼，有没有 &#94;M 之类的刺眼字符，没有就OK。有的话vi下面还是 :%s/\\r//g ， 全局替换下就好。 然而惨痛的就是 I thought I have finished that but... 。这个 \\r 还是曾经出现在我的gff、fasta等等文件中。 而且最悲催的是对于这个东西，使用 less ， head , tail 之类在CLI里面是完全显示不出来的。而有些文件又实在是大到不愿意用vi打开做检查。 反思了一下，犯错的首要可能是因为我使用了多种而不是一种方法来解决这个问题，比如之前我会用Biopython的SeqIO读写一次fasta来消灭回车，也会用vi打开再全局取代，如果只强制自己sed一把，应该就不会再掉这坑了。 天坑收录中，随时更新","tags":"中文","title":"Win下填坑实录"},{"url":"http://runsheng.github.io/guan-yu-quan-zhan-ngsyuan-gong-de-tao-lun-he-si-kao.html","text":"昨天吃饭时候和实验室人闲聊，扯到一个问题，就是 有没可能一个人把NGS(RNA-seq/DNA-seq/ChIP-seq)从做实验到分析数据，再到写文章一个人全干了呢? 当时是没想太多，但是越想越觉得这个问题其实是很现实的问题，牵扯的是在一个传统生物实验室中，实验和生信两拨人怎么合作，怎么判断贡献的问题。 由于我也算是实验转生信的，对两部分的认识应该是偏颇比较少的。 简单的列一下实验和生物信息需要的技能知识如下: 实验部分 按照步骤顺序应该是： 1. 核酸提取。 对于RNA和DNA的测序来说，这部分实在简单不止一晒，分子生物学入门实验。当然，依然需要牢记分子生物第二常识： \"Protocol几乎总是对的，但是它不会强调它在什么情况下是对的\"。 这里面坑也很多，比如某些文库需要的长链DNA怎么回收比较好之类的细节，需要领域专门知识才能解决。 ChIP-seq会麻烦一点，它要求你至少能做ChIP(染色质免疫沉淀)，并且会做像样的质控 (阳性对照阴性对照都跑好了才敢上机啊)。可以算是有一个小门槛。 2. 文库的制备 首先这些东西全都得按kit来，所以其实最需要的是阅读说明书的能力。 DNA文库没有反转录, Illumina的Trueseq、Nextera用的很多，NEB、罗氏、kapa之类的也能用，大同小异。 RNA文库可能多出一步反转录， 还有一步是mRNA的富集或者是rRNA的去除， 也是kit能做的事情。 ChIP-seq和DNA是一样的， 但是Nextera这种灵活性差的kit就不能用了。 3. 上机 首先要知道上什么机器， 小实验室一般是Miseq之类通量较小的。 然后其实上机的主体flow cell(不知道怎么翻译了， 流动槽？)也会被包在Illumina的Kit里，能力需求同上。 上机之前文库要做质控吧？Trueseq的还要定量吧？那么会跑Realtime PCR是基本。 4. 机器养护？ 如果是个小实验室，可能还会需要自己自己维护仪器，不过这个和实验技能的关系就不大了，主要是管理问题。暂略。 总结 NGS这一块的实验至少需要的技能主要是分子生物实验室基本常识及操作，包括但不限于： 会用移液器、离心机、磁力架 会跑胶回收DNA、磁珠回收DNA 会各种PCR 会读protocol并能做好每步质控以便debug--这个要求其实就是很高的了， 基本相当于生信上的\"为了保证代码可复用所以每部分的单元测试都要写好\"的难度。当然，如果做不到，也是可以成功的，不过要做好准备交很多学费。 生物信息部分 这部分其实应该跟着实验走，毕竟分析RNA-seq和分析ChIP-seq的共通之处还真就不是很多， 按照流程应该是： 1. 选择分析软件并使用 比如RNA-seq，一般是为了拿差异表达基因，那么你可以选tophat->cufflinks，无参可能会选trinity->RSEM->blast2GO, 也可能直接用是CLC来做。 DNA-seq， 重测序可能为了找各种变异，那么indel and SNP caller比如GATK之类就要至少会一个。要组装的话de nove assembler要自己选好。OLC还是DBG， 选择一大堆，需要自己试。 ChIP-seq主要只是选个peak calling的软件，MACs，PeakSeq之类的 mapping软件的选择， 知道几种mapper是有区别的， 并且能简单评价在什么情况下用什么mapper可能更好就够了。 2. 展示并交流数据 会画图展示自己的分析结果 数据从机读到人读的转化， 至少要做得比测序公司的报告更加人性化，便于理解，不然饭碗不保。 某些人喜欢用网页作为终端展示，那么就需要一点前端知识。 总结 这个其实是很宽泛的说法， 比如最小技能应当有 Linux 基础，毕竟要装很多开源的学界软件。 熟练一门编程语言，能够让你熟练处理字符串，并画出某些图。 perl，python之类？甚至excel宏写的好我觉得也足够。 基础的统计学知识，嗯，确实是统计而不是数学。比如你可以不懂DBG但是照样用abbsy做从头组装，但是你不能不懂置信区间就去筛差异表达基因。 熟悉专有数据库接口，比如GO，KEGG，各个genome browser。以确保你一旦需要什么做分析，马上可以拿到手。 当然，上面这些说的只是NGS需要的最小知识。纯粹的bioinformatics一直都不是bio而只是informatics。 成为 全栈NGS从业者 只是一半的人学另一半的知识那么简单么? 那么技能列完了， 回到最开始的问题， 如果要成为 全栈NGS 分析人是不是掌握两边的最小技能就行了呢？ 恐怕只存在理论上的可能性。 首先，指望一个专业是生物信息的学生去学做实验，并做的非常努力是不现实的，因为无论如何，扯到informatics的工作报酬一般会比做wet lab的要高，而且如今的编程活动也容易养成一些奇怪的自尊和自大。我并不为此感到奇怪，抛开IT人经常被类似于\"创造\"和\"掌控\"之类的情感所熏陶带来的影响，现在的computer science 是\"显学\"。而\"显学\"从业者的平均傲娇程度可以参考战国中期的儒门，中世纪的传教士，十九世纪的物理学家。这个时代距离真理最近的一群人(自称)跟你们这帮P民有什么好解释的？大家根本不在一个频道上嘛。 \"He is a lamb, he is a women, he never exists. And now he is an IT man!\" 《The Man From Earth》, AD2007 那么是不是说做实验的人转到生信上就会容易呢？首先可以肯定是会简单一点，因为为了吃生物这晚饭，不得不去转变知识结构，这些人的动力会足一点。毕竟现在的生信就像是80年代的分子生物学，你不学不行，不学实验室就有被淘汰的风险，所以现在的生信培训才会一浪高过一浪（虽然并卵）。但是现在几乎公认的是，计算机这门\"显学\"对一直大部分拿移液器加样的生物民工来说，其门槛稍微有些高了，在正常的lab干过的都知道，繁重的体力劳动以及定时定点的实验处理会牵扯大部分精力，留下的有效学习时间很是有限。如果有幸碰到nice点的老板，才可能有机会完成这个转型（有人说是相反，nice的老板会让你留在纯实验，hash的老板才会让你下决心转型）。 而门槛究竟算是多高，在这里我就不敢多说了，毕竟 文人如范仲淹，始足以讲武；武将如岳鹏举，始足以谈文 。 倒是可以看MACs作者刘小乐的 这篇 ，作为生信PI的人对如何与湿实验的人合作，看法不是我等P民能瞻仰的。 被忽略的核心问题 对于想要在学界生存下去的人，最核心的问题还是\"不发表就死亡\"。发表文章的问题才是核心问题。 虽然NGS的冲击曾经改变过一些文章发表的套路，但是很快就又变回去了。没有好的生物学故事，没有好的实验材料，\"全栈\"的梦想还是白扯。掌握这两方面的技能并不能使文章的发表变得更简单，只要做生物，还是生物为先；做方法的，依然是方法为先。PI不改思路不改方向不玩\"全栈\"，员工永远只是经济适用型的，\"全栈\"也没办法增加你的身价。 现在有些实验室，扔钱出去测了东西，然后拿了数据回来，扔到做生信的人面前，曰：\"嗟，来分析，赏作者\"。这个是很麻烦的，因为实话实说，测序公司的制式报告已经把该包括的基本都包括了，当然不该包括的大部分也有，你不提供具体的实验设计，也没有大致的分析方向，而是希望在该领域一窍不通甚至在生物上都完全没概念的员工做出成品的文章，这怎么可能呢？ \"How can it be?\" —— runsheng, AD2010 作为做实验的人，你要做的角色是PM，而不是客户啊，客户改需求可以不管程序员死活，PM要是整死了你手下的程序员，你离滚蛋也就不远了啊。这个道理似乎也是很难懂得呢。 于是到头来： 汝果欲学诗，功夫在诗外。 —— 陆游，AD1208 最终还是免不了鸡汤的俗！ runsheng","tags":"中文","title":"关于\"全栈NGS\"员工的讨论和思考"},{"url":"http://runsheng.github.io/r-packages-xin-shu-pdfzi-xing-bian-yi-ubuntu-1404.html","text":"前段日子Hadley Wickham的新书 'R packages'也算是上线了，美亚有售 实体版 。 不过本书的所有资源包括原文和代码都可以在 github 以及 网站 上找到，所以其实是开源的。 网页版本很漂亮读起来也很不错甚至可以本地编译网站(Ruby based)，但是我辈diaosi还是想看pdf。 Hadley其实写了build-book.r，只要有R和LaTeX就可以生成pdf，步骤简介如下(看了 Brett Klamer的blog , 一路走下来,果断没成...稍微改了下步骤): 1. 下载 git clone https://github.com/hadley/r-pkgs/ 可以看到/book/目录下的build-book.r, 里面需要载入rmarkdown和bookdown两个library.所以下载之. 2. devtool安装rmarkdown和bookdown install.packages ( \"devtools\" ) # 先装devtools devtools :: install_github ( \"hadley/devtools\" ) # devtools更新为Hadley的开发版,可以不做 devtools :: install_github ( c ( \"rstudio/rmarkdown\" , \"hadley/bookdown\" )) 其中 devtools::install_github(\"hadley/devtools\") ,在现在的版本(2015/06/29)不执行也行. 3. 从CRAN安装所有依赖包 install.packages ( c ( \"knitr\" , \"pryr\" , \"nycflights13\" , \"png\" , \"stringi\" , \"lubridate\" , \"testthat\" )) 主要是bookdown的依赖包. 4. XeLaTeX以及附加字体库，ubuntu可以apt装. sudo apt-get install texlive-xetex sudo apt-get install fonts-inconsolata sudo apt-get install texlive-xetex-extra 需要包括字体库upquote.sty和emptypage.sty (在texlive-xetex-extra里打包了), 如果想单装,在debian里面还是比较麻烦, 因为tlmgr install在debian里面是不能用的~ 5. 运行 /book/build-book.r文件 直到最后一行返回TRUE才是正确的生成了PDF文件\"r-packages.pdf\"，文件可以在/book文件夹找到. file.copy(\"book/tex/r-packages.pdf\", \"book/r-packages.pdf\", overwrite = TRUE) [1] TRUE 如果有X和Rstudio，自然是用Rstudio打开r-pkgs.Rproj文件，之后打开/book/build-book.r文件逐行运行. 比如我第一次运行在46行 system(\"xelatex -interaction=batchmode r-packages \") 卡住 只显示 \"This is XeTeX, Version 3.1415926-2.5-0.9999.3 (TeX Live 2013/Debian) restricted \\write18 enabled. entering extended mode\" 而没有停顿, 这是因为LaTex缺少了字体文件而没有工作, 装了texlive-xetex-extra之后就好了.（注: 这个warning是正常信息，restricted \\write18 并不影响最终PDF的生成). 附上编译的例子: 点我 . 2015/06/29,由于本书还在频繁更新,要看还是自己弄个吧.","tags":"中文","title":"R packages 新书 PDF自行编译 (ubuntu 14.04)"},{"url":"http://runsheng.github.io/shi-yong-pelicanda-jian-ji-yu-gitde-jing-tai-bo-ke.html","text":"缘由 最终还是决定把博客挪到github上, 因为还是要用win, endnote重度依赖是一方面.处理\"excel达人\"遗留的神奇宏绘图是另一方面. 所以不得不在win下配好pelican. 最小环境配置 git必装, github选装, 如果装了github, 那么win下的gitbash还算功能不错, git自带的那个bash实在是不甚好用 python环境,我是python2.7.10 pip一定要配好 用不用virtualenv全看个人喜好 GNU make for win , 稍微有点麻烦,装好了还得记得加环境变量. 写markdown的编辑器得有个,我现在拿sublime写,开着vim model(就是大家说的真-神经病模式). 但是说实话win下gvim太难用了, 不算是真正能投入使用的工具, 没有偏爱的文本编辑器的话, notepad其实也可一用. 装装装 pip install pelican pip install markdown 建个文件夹比如d:/blog之类的,进去,开cmd pelican-quickstart 一路回车下来, 这些问题其实是回答pelicanconf.py的一些参数, 可以随便写了之后再改. 比如我的配置是 #!/usr/bin/env python # -*- coding: utf-8 -*- # from __future__ import unicode_literals AUTHOR = u'Runsheng' SITENAME = u'Buskined bioinformatics' SITEURL = '' PATH = 'content' TIMEZONE = 'Asia/Shanghai' DEFAULT_LANG = u'en' 建一个测试页面试下 在 content 目录里面随便写个 test.md, 其中Title, data, Author三项必须有,否则 duang~ 另外data的支持形式还算多样: 2015/06/17, 2015-06-17之类的都没问题 Title: 使用pelican搭建基于git的静态博客 Date: 2015/06/17 Category: 中文 Tags: python Author: runsheng 之后回到 blog 根目录, 也就是makefile在的地方, make html . 该命令其实等价于 pelican D:/blog/content/ -o D:/blog/output -s D:/blog/pelicanconfg.py . 也就是说如果不幸 GNU make 装不好的话也是有办法运行pelican的. 可喜可贺,可喜可贺啊. 生成的网页文件在/output下面. 如果通过了,'make serve'就可以在'localhost:8000'看下了. 精雕细琢 换主题 在blog目录下,把所有集成主题全部拿下一个个挑 git clone --recursive https://github.com/getpelican/pelican-themes 结果最后还是用了bootstrap变体, pelican-bootstrap3, 这个主题现在有个小坑, 在使用tipue_search插件搜索的时候, 搜索到的结果会返回 undefined. 不过这个分支 https://github.com/phips/pelican-bootstrap3/tree/bump_tipue_to_v5/ 可以解决这个问题, 看到已经提交了pull request. 把改动的几个css和js放到 pelican-bootstrap3/static/tipuesearch下面替换现有文件即可. 根据主题选插件 在blog目录下,把所有集成插件全部拿下 git clone --recursive https://github.com/getpelican/pelican-plugins 虽然大部分插件都是全主题可用的,但是也存在好用与否的问题, 有些插件在原生主题上就需要你自己改base.css才能用,所以尽量配套选,避免麻烦. 最终状态 PLUGIN_PATHS = ['D:/blog/pelican-plugins'] PLUGINS = ['summary','sitemap','neighbors','tipue_search','tag_cloud'] DIRECT_TEMPLATES = ('index', 'categories', 'authors', 'archives', 'search') tipue_search 在 PLUGINS 中加入 'tipue_search' ,在 DIRECT_TEMPLATES 加入 'search' , 见上面最终状态。 tag_cloud 老实说,这个是不得不用,如果不打开,那么 tag 显示永远为空. 在 PLUGINS 中加入 'tag_cloud' ,config文件中写入 DISPLAY_TAGS_ON_SIDEBAR = True TAGS_URL = \"tags.html\" tag_cloud = True sitemap 在 PLUGINS 中加入 'sitemap' ,这样每次make html之后会生成site.xml文件供搜索. SITEMAP = { 'format' : 'xml' , 'priorities' : { 'articles' : 0.7 , 'indexes' : 0.5 , 'pages' : 0.5 }, 'changefreqs' : { 'articles' : 'monthly' , 'indexes' : 'daily' , 'pages' : 'monthly' } } Disqus评论账户 git只存储静态网页,动态的评论可以托管给 Disqus 系统,国内的比如 多说 其实也可以, 但是原生theme不支持, 需要插件. DISQUS_SITENAME = 'Shortname' Google Analytics 拿到的 tracking ID 是 'UA-00000000-0' 格式的 GOOGLE_ANALYTICS = 'Tracking ID' google站长工具还是很好用的。 预览没问题就可推到git上去了(以github为例) github建一个repo, 名字为runsheng.github.io 这个名字必须是 用户名.github.io 或者 用户名.github.com 的形式 进入gitbash, 切到/blog/output目录下 把生成的静态页面推到github page上. git init git add . git remote add origin https://github.com/runsheng/runsheng.github.io git pull origin master git commit \"add html\" git push origin master 之后就可以访问 runsheng.github.io 了. 填坑实录, pelicanconf.py 参数重设 （2015/07/07更新） 1. 需要注意的是PATHS参数现在同意接受list而不是string作为参数了,当然 PLUGIN_PATHS = 'D:/blog/pelican-plugins' 也能用, 但是会出warning. 2. pelican-bootstrap3这个主题，在使用tipue_search插件搜索的时候, 搜索到的结果会返回 undefined. 不过这个分支 https://github.com/phips/pelican-bootstrap3/tree/bump_tipue_to_v5/ 可以解决这个问题, 看到已经提交了pull request. 把改动的几个css和js放到 pelican-bootstrap3/static/tipuesearch下面替换现有文件即可. 3. DISQUS_SITENAME的评论有些网页能加载，有些不能，会返回\"We are unable to load Disqus...\" 本人实在JS debug无力。根据官方文档的说法，很可能是因为disqus_url由相对路径生成，但是生成的其实不对。针对这个倒是可以改下参数： SITEURL = 'http://runsheng.github.io' RELATIVE_URLS = False 似乎问题是解决了，不过这样就没办法在本地预览评论了，需要推上git之后才能看到。 4. pelican-bootstrap3这个主题必须使用tag_cloud插件，否则tag不能正常显示 5. 未解决，百度收录问题。 google站长工具很好用，提交url很方便。 相应的百度就是不友好的典型了。首先百度爬虫（他们自己叫蜘蛛）是被github限制了访问的，抓不到网站是正常。手动提交网址链接之后依旧全无反应，搁置了。","tags":"中文","title":"使用pelican搭建基于git的静态博客"},{"url":"http://runsheng.github.io/quick-guide-for-parameters-in-tophat-cufflinks-in-nematode-rna-seq-analysis.html","text":"The summary of tophat-cufflinks protocol is like that: step1: generate a tophat_out folder with bam files tophat -G genes.gtf <index> sample1_1.fq sample1_2.fq tophat -G genes.gtf <index> sample2_1.fq sample2_2.fq step2: generate new .gtf files (assemble isoform) cufflinks sample1/accepted_hits.bam cufflinks sample2/accepted_hits.bam step3: prepare a text file named assemblies.txt with following gtf files cat << EOF > assemblies.txt >sample1/transcript.gtf >sample2/transcript.gtf >EOF step4: run cuffmerge to generate merged.gtf cuffmerge -g genes.gtf -s genome.fa assemblies.txt step5: compare gene expressions of two samples cuffdiff merged.gtf sample1/accepted_hits.bam sample2/accepted_hits.bam The protocol specifically used for our data step0: access to the data Open the web serve at , the passwd is The result can be downloaded and viewed in *** in the shell, type: 'cd ~/new2/RNAseq/trim' step1: generate a tophat_out folder with bam files, using only JU1421-1 as example \"-N 8 \\ --read-gap-length 8 \\ --read-edit-dist 8 \\\" are generally called mismatch, this means the mismatch for the mapping is 8. Using this parameter, we can only find 69% JU1421 reads are mapped. tophat2 -p 15 -i 20 -I 5000 -g 10 \\ -N 8 \\ --read-gap-length 8 \\ --read-edit-dist 8 \\ -o ./tophat_out/JU1421-1 \\ -G ../genome/GENES.gff3 \\ ../genome/cb4_ws242 \\ JU1421-1_S1_L001_R1_001_trimpair.fastq.gz,JU1421-1_S1_L001_R2_001_trimpair.fastq.gz \\ All reads should be mapped using the same parameters. For AF16, the example is: tophat2 -p 15 -i 20 -I 5000 -g 10 \\ -N 8 \\ --read-gap-length 8 \\ --read-edit-dist 8 \\ -o ./tophat_out/AF16-1 \\ -G ../genome/GENES.gff3 \\ ../genome/cb4_ws242 \\ AF16-1_S1_L001_R1_001_trimpair.fastq.gz,AF16-1_S1_L001_R2_001_trimpair.fastq.gz \\ step2: generate new .gtf files (assemble isoform) cufflinks -p 8 -o ./tophat_out/JU1421-1 ./tophat_out/JU1421-1/accepted_hits.bam cufflinks -p 8 -o ./tophat_out/JU1421-2 ./tophat_out/JU1421-2/accepted_hits.bam cufflinks -p 8 -o ./tophat_out/JU1421-3 ./tophat_out/JU1421-3/accepted_hits.bam cufflinks -p 8 -o ./tophat_out/AF16-1 ./tophat_out/AF16-1/accepted_hits.bam cufflinks -p 8 -o ./tophat_out/AF16-2 ./tophat_out/AF16-2/accepted_hits.bam cufflinks -p 8 -o ./tophat_out/AF16-3 ./tophat_out/AF16-3/accepted_hits.bam step3: prepare a text file named assemblies.txt with following gtf files cat << EOF > assemblies.txt >JU1421-1/transcript.gtf >JU1421-2/transcript.gtf >JU1421-3/transcript.gtf >AF16-1/transcript.gtf >AF16-2/transcript.gtf >AF16-3/transcript.gtf >EOF step4: run cuffmerge to generate merged.gtf cuffmerge -g ../genome/GENES.gff3 -s ../genome/cb4_ws242.fa assemblies.txt step5: compare gene expressions of two samples cuffdiff -p 8 merged.gtf –L JU1421,AF16 \\ ./JU1421-1/accepted_hits.bam, \\ ./JU1421-2/accepted_hits.bam, \\ ./JU1421-3/accepted_hits.bam \\ ./AF16-1/accepted_hits.bam, \\ ./AF16-2/accepted_hits.bam, \\ ./AF16-3/accepted_hits.bam \\","tags":"en","title":"Quick guide for parameters in tophat-cufflinks in nematode RNA-seq analysis"},{"url":"http://runsheng.github.io/start-a-ipython-notebook-server-with-password-login.html","text":"As I finally realized that, to install a rpy2 package on Windows is almost a mission impossible, I decide to install a ipython notebook server on the remote machine instead. So I can generate the R script from python and run by \"R cmd run run.r\". Naive, but it works... The offical website suggest to use SSL in login, however, I may have to use the server with public computer. So password login should be more convenient. Here is the step: 1. First, create a hashed password. In [ 1 ]: from IPython.lib import passwd In [ 2 ]: passwd () Enter password : Verify password : Out [ 3 ]: 'sha1:5dd097...' 2. Create a custom profile for the notebook, with the following command line, type: $ ipython profile create nbserver 3. Change the Config file(ipython_notebook_config.py), add the following lines, c = get_config() # Kernel config c.IPKernelApp.pylab = 'inline' # if you want plotting support always # Notebook config c.NotebookApp.ip = '*' c.NotebookApp.open_browser = False c.NotebookApp.password = u'sha1:5dd097...'[the hashed password generated by IPython.lib.passwd]' # Define a port c.NotebookApp.port = 8888 4. Make it run: ipython notebook --profile = nbserver Then the server can be accessed by using the \"http://server_IP:8888\" , you will have to enter the password for login.","tags":"en","title":"Start a ipython notebook server with password login"},{"url":"http://runsheng.github.io/about-me.html","text":"Runsheng li Current; postdoc @ HKBU PhD; @ NJAU BSc; @ NWSUAF 望海潮/过长江 [2013/11/09于南京] 繁花将尽，金曦尚远，中夜过此长江。 归路几识，长涛漫卷，人世些许风霜。 有皎月清朗， 奈何乱灯碍，难照衣裳。 觅觅寻寻，信知吴楚菲今乡。 何曾止住彷徨！ 笑浮云即吾，胡乱飞扬。 西北东南，三京两镇，参差万里行藏。 当不语离殇。 但放眼极目，层峦叠嶂。 想问何时风起，吹我过高岗。","tags":"aboutme","title":"About me"}]}